{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4690e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6cc536",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e5dd9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my last video, we talked about why podcasts and transcripts are such a powerful combination. In this video, we are going to talk about how. We'll answer questions like, should you listen first or should you read first? Should you listen and read at the same time? How many times should you do every activity? and what is the most effective way to actually make this a part of your English study routine? So, if you've ever asked yourself any of those questions, don't worry. In this video, I will give you a stepbystep guide on how to use podcasts and transcripts to improve your English fluency, and I'll talk you through a 90-minute study routine that is super helpful for English learning. Now, the first step is, of course, to choose a podcast. As I've said many times before, you need to choose one that talks about something that's actually interesting and relevant to you. Look for podcasts that have clear speech, are about a topic that you enjoy, and are at a level that is appropriate for you. Now I think if you can understand somewhere between 70 to 80% of what is being spoken that is the right kind of level for you in terms of how you can actually get transcripts. Some podcasts provide transcripts. If you are listening to a podcast on YouTube, you you can use YouTube's in-built functionality to grab the AI generated transcript. There are also tools like descript or otter where you can get transcripts by uploading an MP3. For the purposes of this video, I am going to use an episode of English learning for curious minds because it's a podcast that has been specifically designed for this. For the past 5 years, I've been making this podcast with transcripts specifically designed for intermediate to advanced learners to improve their English using this method. I'll put a link down below this video where you can get a bunch of free transcripts. All the transcripts are also interactive, so you can hover over words and see definitions in English. We also have translations in 12 different languages. So, it makes it really easy to learn from. Again, I'll put a link down below this video so you can go and check that out for yourself if you'd like. Okay, moving on. How do we actually get started? The first thing to do might surprise you given that we're talking about podcasts and transcripts is that first I recommend you listen without the transcript. Just forget about the transcript for the first listen. So just press play, close your eyes so there are no distractions and just listen. Try to listen for overall meaning and try to understand what is being said. It doesn't matter if you don't understand everything. That is completely to be expected. That is real life. The objective of this first bit is to train your ears and your brain to understand real life English. So, first just listen, forget about the transcript. The second step is to go back and listen again, this time with the transcript next to you. And this is where the magic really happens. As you're listening and you're reading the transcript at the same time, you'll find that you'll notice, you'll pick up all the little details that you might have missed the first time round. So the words that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the transcript to check to confirm everything that you think you have heard. When you are listening with the transcript, I would encourage you to press pause and to look at words, phrases that you found difficult to understand. You can go back and try to listen to something again to catch it for the second time. So here you're trying to really engage with the podcast on a deeper level than you did the first time when you just listened. If you're the sort of person who likes to print things out, you can print things out and and circle them, highlight interesting words and so on, scribble all over the all over the transcript. If you're the sort of person who prefers to keep everything digital, then this was probably a good opportunity for adding little words to your your Anki flashcards or whatever it might be. So, you're just trying to engage with the language on a deeper level. The third thing I'd recommend you do is one of my favorite techniques, and this is something called shadowing. Now, in case you've never heard of shadowing before, here's how it works. You listen to a sentence. So, choose a sentence from the podcast. You press pause. You try to repeat exactly as the speaker said. Then go back a little bit and repeat exactly what they said, exactly as they said it. So, you're trying to match the exact pronunciation, the stress, the rhythm, and the intonation. Essentially, you're copying exactly what the speaker said and how they said it. You're mimicking every single aspect of their speech. Now, many people when they try this for the first time say it feels difficult. It feels kind of unnatural. That is fine and completely expected. In fact, it's a good thing because you're stretching muscles and pushing yourself further than you would be doing otherwise. So, you're really training your mouth to create sounds that you wouldn't be doing otherwise. Yes, it might feel unnatural, but the irony of this is that the more you do it, the more natural your English will start to sound. Now, I wouldn't recommend you do shadowing for much longer than five or 10 minutes because it is quite an intensive activity, but it is incredibly powerful. Activity number four, the next thing that I would do is to mine the transcript for vocabulary. So go through it almost line by line and think of yourself as a collector of interesting words, phrases, and grammatical structures. Now, I talked about this in detail in another video, but as a brief reminder, I think about vocabulary in three different categories. There's category one, which is words that you know if you hear them and you know how to use. There is category three which is words that you don't know if you hear them and therefore you don't know how to use them. But there's this second category which is words that you know if you hear them but that you wouldn't necessarily use in your own speech. And this is where I think everyone should focus. So this can be things like kind of common collocations things like take a break or pay attention. It can be kind of useful expressions that help you move from one subject to another. So on the one hand or let's dive in or if that wasn't enough. It's those kind of things that I think you should really focus on and transcripts can be super helpful for allowing you to highlight these kinds of words and phrases. So go through the transcript and try to collect this type of vocabulary. Now, it's always important to be reasonable when it comes to how many words you can actually learn from a podcast episode. I really wouldn't aim for more than 10 per episode because if you try to tell yourself, I'm going to try and learn 50 words per episode or 100 words and expressions per episode, that is really, really challenging. And my experience, my opinion is that by setting your goals so high, you're really just setting yourself up for failure and disappointment. So, best to try and focus on a few words and expressions and learn them really thoroughly rather than try to note down absolutely everything new from a podcast episode. So, pick a few, let's say five to 10, note them down. If you use something like Anki, then add it to a flashcard app like that. And make sure you review this on a regular basis. So here you're turning passive vocabulary knowledge from what you've heard into active vocabulary acquisition. And you'll find that those words that were previously in category number two, words that you understood but wouldn't use, will shift into category number one. words that you understand and words that you use in your own English speech and writing. And the final activity you can do is one that seems very simple, but is one that not many people do at all. And that is to summarize the episode. And you can do this in two different formats. And they are both a lot easier and a lot less time consuming than you might think. The first is to summarize it by speaking. So imagine that you are with a friend and the friend said, \"What was that podcast episode about?\" You need to tell them. But here it's very useful to give yourself some boundaries, some constraints, some limits around what you're going to do. So, what I would do here is open up the recording app on your phone, press record, and try to do everything in under 1 minute. Press record and press stop when it gets to 60 seconds. So, what you need to do is try speaking without interruption or trying to pause as little as possible for 60 seconds talking about what the podcast episode was about. Now, it might seem strange to record yourself, but it's very helpful because you can go back and listen to what you said and you will start to recognize mistakes that you've made. You'll start to recognize words that you use too often and you'll be able to correct yourself in a way that you wouldn't be able to do if you hadn't recorded yourself. And this only takes 60 seconds, right? So, it's really not such a timeconsuming activity to do after you've listened to a podcast. You can also try to summarize the episode in written form. So again, I would give yourself some limits here. I would take out the timer on my phone and set it for five minutes. So say, I'm going to sit down and I'm going to try to write a summary of the episode in 5 minutes. It doesn't matter if you don't cover everything. You could even set the timer to 10 minutes if you think that 5 minutes is too little. And again, you can use the transcript as a support, as a crutch for your summary. You can try to use those more complicated words and expressions, vocabulary that was used in the podcast in your own summary. So, this is a really helpful skill because it's taking input in the form of the the audio that you are listening to and the reading that you've done of the transcript and forcing you to turn this into active production of English in terms of speaking out loud and practicing your writing. Okay, so as a quick recap of what to do, first listen once to the podcast without pausing or looking anything up. Let's say it's a 20-minute podcast, so that takes 20 minutes. Listen again with the transcript, pausing to look things up or double check things. Again, let's say a 20-minute podcast, so that might take 30 minutes. Then shadowing, which can take a maximum of 10 minutes. Then mining the transcript for vocabulary, focusing on that second category, vocabulary. That can take 20 minutes. And finally, summarizing the episode, which should take no more than 10 minutes. Added all together, that takes 90 minutes and is an incredibly powerful set of activities that can turn what would otherwise be just a podcast episode into an incredibly valuable learning activity that will help you improve your listening, speaking, writing, reading, and even pronunciation. And you don't need to do it all at once. You can split those activities over multiple days. They're all under 30 minutes long, so they are very manageable, even for those of you with busy personal and professional lives. So sometimes you don't need new materials or revolutionary hacks or tricks. You just need a better way to use what you already have. So go and find an episode of your favorite podcast. As I said, there's also a link to all the free transcripts for English learning for curious minds. Try these activities and let me know how you get on.\n"
     ]
    }
   ],
   "source": [
    "# extract the transcript\n",
    "V_id=\"zIGQ9p6mxUg\"\n",
    "try :\n",
    "  trans_list=YouTubeTranscriptApi.get_transcript(V_id,languages=[\"en\"])\n",
    "  transcript=[i[\"text\"] for i in trans_list]\n",
    "  transcript_f=\" \".join(transcript)\n",
    "  print(transcript_f)\n",
    "\n",
    "except TranscriptsDisabled:\n",
    "    print(\"no caption availiable\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "90dedb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"In my last video, we talked about why podcasts and transcripts are such a powerful combination. In this video, we are going to talk about how. We'll answer questions like, should you listen first or should you read first? Should you listen and read at the same time? How many times should you do every activity? and what is the most effective way to actually make this a part of your English study routine? So, if you've ever asked yourself any of those questions, don't worry. In this video, I will give you a stepbystep guide on how to use podcasts and transcripts to improve your English fluency, and I'll talk you through a 90-minute study routine that is super helpful for English learning. Now, the first step is, of course, to choose a podcast. As I've said many times before, you need to choose one that talks about something that's actually interesting and relevant to you. Look for podcasts that have clear speech, are about a topic that you enjoy, and are at a level that is appropriate\")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divided to sub document\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "'''\n",
    "every document will have 1000 character > max\n",
    "next document will have the last 200 character from the previous document >> to keep track the context\n",
    "'''\n",
    "sub=splitter.create_documents([transcript_f])\n",
    "\n",
    "len(sub)\n",
    "\n",
    "sub[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "90c39cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x21c7541bda0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# converted to numerical representation using embedding\n",
    "\n",
    "embd = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#text-embedding-3-small >> suatiable for semantic search\n",
    "vector=FAISS.from_documents(sub,embd)\n",
    "# convert it to vector assign an index for each vector \n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "42ea6bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '9e98c1b5-6f33-4824-a531-63ef3043e885',\n",
       " 1: '0600d6f9-f7a4-4693-adb1-0d8b2b22a359',\n",
       " 2: '610d68f9-f810-4084-b92b-f765172b2ff0',\n",
       " 3: 'c8cfc2ce-9065-4567-b196-72f21b7cf7c9',\n",
       " 4: 'a421e55f-1151-4ecf-a632-341c668eb4a5',\n",
       " 5: 'cc49ae14-40d4-4add-a535-80192045bb49',\n",
       " 6: 'bf6e716d-558c-4ebd-a69b-b3ff831d9e7e',\n",
       " 7: 'f4b8df01-1874-4bf1-9642-292787e06e9d',\n",
       " 8: '17366ec6-3b85-4d0d-862d-40bbc6b735b5',\n",
       " 9: '741dc8a7-73bf-4b94-b18a-6de83263202a',\n",
       " 10: 'e121e6c3-9f48-4f98-86da-91a6e47680ae',\n",
       " 11: '4684182c-2117-43a1-b6e7-086c228678a9',\n",
       " 12: '6b4fcaaa-5d9c-4ce9-a633-d3bc5edb8723',\n",
       " 13: 'e4e7860a-22d5-4d7c-bbc5-7c5bf07e2a2c',\n",
       " 14: 'f41e6911-9711-4006-b103-aa9eb2a3dea9'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "docstore > فيه عنوان النص نفسه\n",
    "\n",
    "index>      \n",
    "هو رقم الـ \n",
    "vector \n",
    "داخل \n",
    "FAISS index \n",
    "ده موقعه داخل الفهرس اللي بيتخزن فيه الـ \n",
    "embeddings\n",
    " \n",
    "'''\n",
    "vector.index_to_docstore_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c6949ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.get_by_ids(['c6c605da-f29f-4978-9902-b6c5ba74e75f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b88e4",
   "metadata": {},
   "source": [
    "# Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6f37c59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000021C7541BDA0>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query > retriver > semmantic search > vector> most relevent document\n",
    "\n",
    "ret=vector.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":4})\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17eb9827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c8cfc2ce-9065-4567-b196-72f21b7cf7c9', metadata={}, page_content=\"the transcript for the first listen. So just press play, close your eyes so there are no distractions and just listen. Try to listen for overall meaning and try to understand what is being said. It doesn't matter if you don't understand everything. That is completely to be expected. That is real life. The objective of this first bit is to train your ears and your brain to understand real life English. So, first just listen, forget about the transcript. The second step is to go back and listen again, this time with the transcript next to you. And this is where the magic really happens. As you're listening and you're reading the transcript at the same time, you'll find that you'll notice, you'll pick up all the little details that you might have missed the first time round. So the words that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the\"),\n",
       " Document(id='a421e55f-1151-4ecf-a632-341c668eb4a5', metadata={}, page_content=\"that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the transcript to check to confirm everything that you think you have heard. When you are listening with the transcript, I would encourage you to press pause and to look at words, phrases that you found difficult to understand. You can go back and try to listen to something again to catch it for the second time. So here you're trying to really engage with the podcast on a deeper level than you did the first time when you just listened. If you're the sort of person who likes to print things out, you can print things out and and circle them, highlight interesting words and so on, scribble all over the all over the transcript. If you're the sort of person who prefers to keep everything digital, then this was probably a good opportunity for adding little words to your your Anki flashcards or\"),\n",
       " Document(id='9e98c1b5-6f33-4824-a531-63ef3043e885', metadata={}, page_content=\"In my last video, we talked about why podcasts and transcripts are such a powerful combination. In this video, we are going to talk about how. We'll answer questions like, should you listen first or should you read first? Should you listen and read at the same time? How many times should you do every activity? and what is the most effective way to actually make this a part of your English study routine? So, if you've ever asked yourself any of those questions, don't worry. In this video, I will give you a stepbystep guide on how to use podcasts and transcripts to improve your English fluency, and I'll talk you through a 90-minute study routine that is super helpful for English learning. Now, the first step is, of course, to choose a podcast. As I've said many times before, you need to choose one that talks about something that's actually interesting and relevant to you. Look for podcasts that have clear speech, are about a topic that you enjoy, and are at a level that is appropriate\"),\n",
       " Document(id='f4b8df01-1874-4bf1-9642-292787e06e9d', metadata={}, page_content=\"thing that I would do is to mine the transcript for vocabulary. So go through it almost line by line and think of yourself as a collector of interesting words, phrases, and grammatical structures. Now, I talked about this in detail in another video, but as a brief reminder, I think about vocabulary in three different categories. There's category one, which is words that you know if you hear them and you know how to use. There is category three which is words that you don't know if you hear them and therefore you don't know how to use them. But there's this second category which is words that you know if you hear them but that you wouldn't necessarily use in your own speech. And this is where I think everyone should focus. So this can be things like kind of common collocations things like take a break or pay attention. It can be kind of useful expressions that help you move from one subject to another. So on the one hand or let's dive in or if that wasn't enough. It's those kind of\")]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.invoke(\"listen first or read first ?\")\n",
    "# need to join it to put in relevent context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49247b4c",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d4d5d8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\arwah\\anaconda3\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\arwah\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain) (0.3.67)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\arwah\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6fb6a7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c8cfc2ce-9065-4567-b196-72f21b7cf7c9', metadata={}, page_content=\"the transcript for the first listen. So just press play, close your eyes so there are no distractions and just listen. Try to listen for overall meaning and try to understand what is being said. It doesn't matter if you don't understand everything. That is completely to be expected. That is real life. The objective of this first bit is to train your ears and your brain to understand real life English. So, first just listen, forget about the transcript. The second step is to go back and listen again, this time with the transcript next to you. And this is where the magic really happens. As you're listening and you're reading the transcript at the same time, you'll find that you'll notice, you'll pick up all the little details that you might have missed the first time round. So the words that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the\"),\n",
       " Document(id='a421e55f-1151-4ecf-a632-341c668eb4a5', metadata={}, page_content=\"that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the transcript to check to confirm everything that you think you have heard. When you are listening with the transcript, I would encourage you to press pause and to look at words, phrases that you found difficult to understand. You can go back and try to listen to something again to catch it for the second time. So here you're trying to really engage with the podcast on a deeper level than you did the first time when you just listened. If you're the sort of person who likes to print things out, you can print things out and and circle them, highlight interesting words and so on, scribble all over the all over the transcript. If you're the sort of person who prefers to keep everything digital, then this was probably a good opportunity for adding little words to your your Anki flashcards or\"),\n",
       " Document(id='f4b8df01-1874-4bf1-9642-292787e06e9d', metadata={}, page_content=\"thing that I would do is to mine the transcript for vocabulary. So go through it almost line by line and think of yourself as a collector of interesting words, phrases, and grammatical structures. Now, I talked about this in detail in another video, but as a brief reminder, I think about vocabulary in three different categories. There's category one, which is words that you know if you hear them and you know how to use. There is category three which is words that you don't know if you hear them and therefore you don't know how to use them. But there's this second category which is words that you know if you hear them but that you wouldn't necessarily use in your own speech. And this is where I think everyone should focus. So this can be things like kind of common collocations things like take a break or pay attention. It can be kind of useful expressions that help you move from one subject to another. So on the one hand or let's dive in or if that wasn't enough. It's those kind of\"),\n",
       " Document(id='9e98c1b5-6f33-4824-a531-63ef3043e885', metadata={}, page_content=\"In my last video, we talked about why podcasts and transcripts are such a powerful combination. In this video, we are going to talk about how. We'll answer questions like, should you listen first or should you read first? Should you listen and read at the same time? How many times should you do every activity? and what is the most effective way to actually make this a part of your English study routine? So, if you've ever asked yourself any of those questions, don't worry. In this video, I will give you a stepbystep guide on how to use podcasts and transcripts to improve your English fluency, and I'll talk you through a 90-minute study routine that is super helpful for English learning. Now, the first step is, of course, to choose a podcast. As I've said many times before, you need to choose one that talks about something that's actually interesting and relevant to you. Look for podcasts that have clear speech, are about a topic that you enjoy, and are at a level that is appropriate\")]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q=\"listen or read first ?\"\n",
    "related_answer=ret.invoke(Q)\n",
    "related_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cbd211ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the transcript for the first listen. So just press play, close your eyes so there are no distractions and just listen. Try to listen for overall meaning and try to understand what is being said. It doesn't matter if you don't understand everything. That is completely to be expected. That is real life. The objective of this first bit is to train your ears and your brain to understand real life English. So, first just listen, forget about the transcript. The second step is to go back and listen again, this time with the transcript next to you. And this is where the magic really happens. As you're listening and you're reading the transcript at the same time, you'll find that you'll notice, you'll pick up all the little details that you might have missed the first time round. So the words that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the\n",
      "that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the transcript to check to confirm everything that you think you have heard. When you are listening with the transcript, I would encourage you to press pause and to look at words, phrases that you found difficult to understand. You can go back and try to listen to something again to catch it for the second time. So here you're trying to really engage with the podcast on a deeper level than you did the first time when you just listened. If you're the sort of person who likes to print things out, you can print things out and and circle them, highlight interesting words and so on, scribble all over the all over the transcript. If you're the sort of person who prefers to keep everything digital, then this was probably a good opportunity for adding little words to your your Anki flashcards or\n",
      "thing that I would do is to mine the transcript for vocabulary. So go through it almost line by line and think of yourself as a collector of interesting words, phrases, and grammatical structures. Now, I talked about this in detail in another video, but as a brief reminder, I think about vocabulary in three different categories. There's category one, which is words that you know if you hear them and you know how to use. There is category three which is words that you don't know if you hear them and therefore you don't know how to use them. But there's this second category which is words that you know if you hear them but that you wouldn't necessarily use in your own speech. And this is where I think everyone should focus. So this can be things like kind of common collocations things like take a break or pay attention. It can be kind of useful expressions that help you move from one subject to another. So on the one hand or let's dive in or if that wasn't enough. It's those kind of\n",
      "In my last video, we talked about why podcasts and transcripts are such a powerful combination. In this video, we are going to talk about how. We'll answer questions like, should you listen first or should you read first? Should you listen and read at the same time? How many times should you do every activity? and what is the most effective way to actually make this a part of your English study routine? So, if you've ever asked yourself any of those questions, don't worry. In this video, I will give you a stepbystep guide on how to use podcasts and transcripts to improve your English fluency, and I'll talk you through a 90-minute study routine that is super helpful for English learning. Now, the first step is, of course, to choose a podcast. As I've said many times before, you need to choose one that talks about something that's actually interesting and relevant to you. Look for podcasts that have clear speech, are about a topic that you enjoy, and are at a level that is appropriate\n"
     ]
    }
   ],
   "source": [
    "full_context=\"\\n\".join(i.page_content for i in related_answer)\n",
    "print(full_context)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f203f",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e612e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content='The context suggests to listen first as the initial step without the transcript to train your ears and brain to understand real life English, and then read along with the transcript to further comprehend the podcast content with the objective to notice the unfamiliar words and expressions, check them in the transcript, and collect them for vocabulary learning. The video will later discuss how to make the most of podcasts and transcripts for English fluency with suggestions for choosing relevant and appropriate podcasts, simultaneously listening and reading, and a 90-minute study routine. Therefore, the answer is to listen first.', tool_call_id=None, tool_calls=None), logprobs=None)], created=1751508659341, id='BperqW', model='HuggingFaceH4/zephyr-7b-beta', system_fingerprint='', usage=ChatCompletionOutputUsage(completion_tokens=111, prompt_tokens=887, total_tokens=998), object='chat.completion')\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    model=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    token=\"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\"\n",
    ")\n",
    "\n",
    "# بنبعت البرومبت على شكل محادثة\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.Answer ONLY from the provided transcript context.If the context is insufficient, just say you don't know.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"question: {Q}\\n\\ncontext:\\n{full_context}:\"}\n",
    "]\n",
    "\n",
    "response = client.chat_completion(messages=messages, max_tokens=1000)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    token=\"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\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6d222",
   "metadata": {},
   "source": [
    "# Building a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d61ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3d02abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formating_docs(related_answer):\n",
    "  context_text = \"\\n\\n\".join(doc.page_content for doc in related_answer)\n",
    "  return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3cf55889",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context': ret | RunnableLambda(formating_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "17df8f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"the transcript for the first listen. So just press play, close your eyes so there are no distractions and just listen. Try to listen for overall meaning and try to understand what is being said. It doesn't matter if you don't understand everything. That is completely to be expected. That is real life. The objective of this first bit is to train your ears and your brain to understand real life English. So, first just listen, forget about the transcript. The second step is to go back and listen again, this time with the transcript next to you. And this is where the magic really happens. As you're listening and you're reading the transcript at the same time, you'll find that you'll notice, you'll pick up all the little details that you might have missed the first time round. So the words that you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the\\n\\nthat you didn't catch, the expressions that you didn't know, how words are written, how the English that you have heard appears on the page, how it is written down. So here you should be using the transcript to check to confirm everything that you think you have heard. When you are listening with the transcript, I would encourage you to press pause and to look at words, phrases that you found difficult to understand. You can go back and try to listen to something again to catch it for the second time. So here you're trying to really engage with the podcast on a deeper level than you did the first time when you just listened. If you're the sort of person who likes to print things out, you can print things out and and circle them, highlight interesting words and so on, scribble all over the all over the transcript. If you're the sort of person who prefers to keep everything digital, then this was probably a good opportunity for adding little words to your your Anki flashcards or\\n\\nthing that I would do is to mine the transcript for vocabulary. So go through it almost line by line and think of yourself as a collector of interesting words, phrases, and grammatical structures. Now, I talked about this in detail in another video, but as a brief reminder, I think about vocabulary in three different categories. There's category one, which is words that you know if you hear them and you know how to use. There is category three which is words that you don't know if you hear them and therefore you don't know how to use them. But there's this second category which is words that you know if you hear them but that you wouldn't necessarily use in your own speech. And this is where I think everyone should focus. So this can be things like kind of common collocations things like take a break or pay attention. It can be kind of useful expressions that help you move from one subject to another. So on the one hand or let's dive in or if that wasn't enough. It's those kind of\\n\\nIn my last video, we talked about why podcasts and transcripts are such a powerful combination. In this video, we are going to talk about how. We'll answer questions like, should you listen first or should you read first? Should you listen and read at the same time? How many times should you do every activity? and what is the most effective way to actually make this a part of your English study routine? So, if you've ever asked yourself any of those questions, don't worry. In this video, I will give you a stepbystep guide on how to use podcasts and transcripts to improve your English fluency, and I'll talk you through a 90-minute study routine that is super helpful for English learning. Now, the first step is, of course, to choose a podcast. As I've said many times before, you need to choose one that talks about something that's actually interesting and relevant to you. Look for podcasts that have clear speech, are about a topic that you enjoy, and are at a level that is appropriate\",\n",
       " 'question': 'listen or read first ?'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke('listen or read first ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_messages(inputs):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer ONLY from the provided context. If the context is insufficient, say 'I don't know'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"question: {inputs['question']}\\n\\ncontext:\\n{inputs['context']}\"}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3619acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content=\"In summary, the final activity suggested is to either summarize the podcast in 60 seconds through speaking or writing, with constraints to challenge yourself to be concise and avoid pauses. Speaking allows for the identification of common mistakes and vocabulary practice, while writing provides deeper engagement with the language. Shadowing involves repeating a sentence from the podcast to imitate the speaker's pronunciation, stress, and intonation. This technique may be challenging for beginners. By listening, pausing, and then repeating exactly as they spoke it. Overall, these exercises help in interacting more intimately with the language after listening to the episode once or twice and using transcripts for assistance in summarizing or flashcards.\", tool_call_id=None, tool_calls=None), logprobs=None)], created=1751508690814, id='zkqy2X', model='HuggingFaceH4/zephyr-7b-beta', system_fingerprint='', usage=ChatCompletionOutputUsage(completion_tokens=133, prompt_tokens=929, total_tokens=1062), object='chat.completion')\n"
     ]
    }
   ],
   "source": [
    "zephyr_chat_client = RunnableLambda(\n",
    "    lambda messages: client.chat_completion(messages=messages, max_tokens=512)\n",
    ")\n",
    "\n",
    "\n",
    "main_chain = (\n",
    "    parallel_chain\n",
    "    | RunnableLambda(build_messages)\n",
    "    | zephyr_chat_client\n",
    "    | RunnableLambda(lambda x: x['content'] if isinstance(x, dict) and 'content' in x else x)\n",
    ")\n",
    "\n",
    "\n",
    "query = \"Can you summarize the video\"\n",
    "answer = main_chain.invoke(query)\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
